{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7be446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from recruitair.job_offers.models import KeyCriteriaResponse\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://nattech.fib.upc.edu:40380/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e8f2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/900495739893713381', creation_time=1759680270113, experiment_id='900495739893713381', last_update_time=1759680270113, lifecycle_stage='active', name='criteria-extraction', tags={'domain': 'recruitair',\n",
       " 'mlflow.experimentKind': 'genai_development',\n",
       " 'task': 'criteria-extraction'}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.langchain.autolog()\n",
    "mlflow.set_experiment(\"criteria-extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa77edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_PROMPT_NAME = \"criteria-extraction\"\n",
    "MLFLOW_PROMPT_VERSION = 1\n",
    "OLLAMA_MODEL = \"dolphin3\"\n",
    "OLLAMA_MODEL_VERSION = \"8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fbbe5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_job_offer = \"\"\"\n",
    "We are looking for a Software Engineer with experience in Python and machine\n",
    "learning. The ideal candidate should have at least 3 years of experience in\n",
    "software development, a strong understanding of algorithms and data structures,\n",
    "and the ability to work in a fast-paced environment. Familiarity with cloud\n",
    "platforms like AWS or GCP is a plus. Excellent communication skills and the\n",
    "ability to work in a team are essential.\n",
    "\"\"\"\n",
    "\n",
    "target = {\n",
    "    \"key_criteria\": [\n",
    "        {\"name\": \"Python Experience\", \"importance\": 5},\n",
    "        {\"name\": \"Machine Learning Knowledge\", \"importance\": 5},\n",
    "        {\"name\": \"3 years Software Development Experience\", \"importance\": 5},\n",
    "        {\"name\": \"Algorithms & Data Structures Understanding\", \"importance\": 4},\n",
    "        {\"name\": \"Cloud Platforms Familiarity\", \"importance\": 3},\n",
    "        {\"name\": \"Communication Skills\", \"importance\": 5},\n",
    "        {\"name\": \"Teamwork Ability\", \"importance\": 4},\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "data = pd.DataFrame({\"inputs\": [{\"job_offer_text\": sample_job_offer}], \"expectations\": [target]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f08b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "@mlflow.trace\n",
    "def predict(job_offer_text: str) -> KeyCriteriaResponse:\n",
    "    llm = ChatOllama(model=f\"{OLLAMA_MODEL}:{OLLAMA_MODEL_VERSION}\", temperature=0)\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{MLFLOW_PROMPT_NAME}/{MLFLOW_PROMPT_VERSION}\")\n",
    "    response = llm.with_structured_output(prompt.response_format, method=\"json_schema\").invoke(\n",
    "        prompt.format(job_offer_text=job_offer_text)\n",
    "    )\n",
    "    return KeyCriteriaResponse.model_validate(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3903983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import Feedback\n",
    "import ollama\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@mlflow.genai.scorer(name=\"target-recall/embedding/mxbai-embed-large:335m\")\n",
    "def target_recall(outputs: KeyCriteriaResponse, expectations: KeyCriteriaResponse) -> Feedback:\n",
    "    expectations = KeyCriteriaResponse.model_validate(expectations)\n",
    "    # Compute the embeddings of the names of the all the extracted and target criteria:\n",
    "    target_embeddings = []\n",
    "    for target_criterion in expectations.key_criteria:\n",
    "        target_embeddings.append(ollama.embed(\"mxbai-embed-large:335m\", input=target_criterion.name)[\"embeddings\"][0])\n",
    "    response_embeddings = []\n",
    "    for response_criterion in outputs.key_criteria:\n",
    "        response_embeddings.append(\n",
    "            ollama.embed(\"mxbai-embed-large:335m\", input=response_criterion.name)[\"embeddings\"][0]\n",
    "        )\n",
    "    # Compute the cosine similarity matrix between the two sets of embeddings:\n",
    "    similarity_matrix = np.inner(np.array(response_embeddings), np.array(target_embeddings))\n",
    "\n",
    "    # We'll score as follows: For each target criterion, we'll find the most similar\n",
    "    # response criterion, thus we'll have, for each target criterion, a score\n",
    "    # between 0 and 1 representing how well it was matched. We'll then floor\n",
    "    # everything below 0.8 to 0, and average the rest.\n",
    "    # This means that if a target criterion was not matched with at least 0.8,\n",
    "    # it will contribute 0 to the average. We'll call this \"target recall score\".\n",
    "    # It can be interpreted as the \"rich fraction\" of target criteria that were well matched.\n",
    "    scores = similarity_matrix.max(axis=0)\n",
    "    target_recall_score = float(np.where(scores < 0.8, 0, scores).mean())\n",
    "    return Feedback(value=target_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d81c7323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/05 19:16:49 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset.\n",
      "Evaluating:   0%|          | 0/1 [Elapsed: 00:00, Remaining: ?] 2025/10/05 19:16:55 WARNING mlflow.tracing.export.mlflow_v3: Failed to log span to MLflow backend: INTERNAL_ERROR: Response: {'detail': 'REST OTLP span logging is not supported by FileStore'}\n",
      "2025/10/05 19:16:55 WARNING mlflow.tracing.export.mlflow_v3: Failed to log span to MLflow backend: INTERNAL_ERROR: Response: {'detail': 'REST OTLP span logging is not supported by FileStore'}\n",
      "2025/10/05 19:16:55 WARNING mlflow.tracing.export.mlflow_v3: Failed to log span to MLflow backend: INTERNAL_ERROR: Response: {'detail': 'REST OTLP span logging is not supported by FileStore'}\n",
      "2025/10/05 19:16:55 WARNING mlflow.tracing.export.mlflow_v3: Failed to log span to MLflow backend: INTERNAL_ERROR: Response: {'detail': 'REST OTLP span logging is not supported by FileStore'}\n",
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:04, Remaining: 00:00] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <title>Evaluation output</title>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "\n",
       "        .header {\n",
       "            a.button {\n",
       "                padding: 4px 8px;\n",
       "                line-height: 20px;\n",
       "                box-shadow: none;\n",
       "                height: 20px;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                justify-content: center;\n",
       "                vertical-align: middle;\n",
       "                background-color: rgb(34, 114, 180);\n",
       "                color: rgb(255, 255, 255);\n",
       "                text-decoration: none;\n",
       "                animation-duration: 0s;\n",
       "                transition: none 0s ease 0s;\n",
       "                position: relative;\n",
       "                white-space: nowrap;\n",
       "                text-align: center;\n",
       "                border: 1px solid rgb(192, 205, 216);\n",
       "                cursor: pointer;\n",
       "                user-select: none;\n",
       "                touch-action: manipulation;\n",
       "                border-radius: 4px;\n",
       "                gap: 6px;\n",
       "            }\n",
       "\n",
       "            a.button:hover {\n",
       "                background-color: rgb(14, 83, 139) !important;\n",
       "                border-color: transparent !important;\n",
       "                color: rgb(255, 255, 255) !important;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .warnings-section {\n",
       "            margin-top: 8px;\n",
       "\n",
       "            ul {\n",
       "                list-style-type: none;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .instructions-section {\n",
       "            margin-top: 16px;\n",
       "            font-size: 14px;\n",
       "\n",
       "            ul {\n",
       "                margin-top: 0;\n",
       "                margin-bottom: 0;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        code {\n",
       "            font-family: monospace;\n",
       "        }\n",
       "\n",
       "        .note {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        a {\n",
       "            color: #2272B4;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "\n",
       "        a:hover {\n",
       "            color: #005580;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "    <div class=\"header\">\n",
       "        <a href=\"http://nattech.fib.upc.edu:40380/#/experiments/900495739893713381/runs/710e30ad5e1149648dc861b81267cc59/traces\" class=\"button\">\n",
       "            View evaluation results in MLflow\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1em\" height=\"1em\" fill=\"none\" viewBox=\"0 0 16 16\" aria-hidden=\"true\" focusable=\"false\" class=\"\">\n",
       "                <path fill=\"currentColor\" d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"></path>\n",
       "                <path fill=\"currentColor\" d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"></path>\n",
       "            </svg>\n",
       "        </a>\n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"prompt-evaluation\"):\n",
    "    mlflow.log_param(\"ollama_model\", OLLAMA_MODEL)\n",
    "    mlflow.log_param(\"ollama_model_version\", OLLAMA_MODEL_VERSION)\n",
    "    mlflow.log_param(\"temperature\", 0)\n",
    "    mlflow.log_param(\"mlflow_prompt_name\", MLFLOW_PROMPT_NAME)\n",
    "    mlflow.log_param(\"mlflow_prompt_version\", MLFLOW_PROMPT_VERSION)\n",
    "\n",
    "    mlflow.genai.evaluate(\n",
    "        predict_fn=predict,\n",
    "        data=data,\n",
    "        scorers=[target_recall],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CriteriaExtractor (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
